# Exposing the Limits of Video-Text Models through Contrast Sets

Repository for [Exposing the Limits of Video-Text Models through Contrast Sets](https://openreview.net/pdf?id=H_Wx_yQfBZq) (NAACL Short 2022).

## Updates
6/24/2022: Released contrast sets for MSRVTT. 

To Do:
 - Release contrast sets for LSMDC
 - Release code to generate contrast sets automatically

## Code
TBD

## Data
We share the verb phrase based contrast set for [MSRVTT](http://ms-multimedia-challenge.com/2017/dataset) and [LSDMC-ID](https://sites.google.com/site/describingmovies/) in this repository.
Code to generate the contrast set will be released soon.

### MSRVTT
The verb based contrast sets generated by language model and humans can be found in `msrvtt/`.
You can find the video and annotation data following this [link](https://github.com/m-bain/frozen-in-time#-finetuning-benchmarks-msr-vtt). The sets are generated for the test set of MSRVTT.

You can additionally refer to download script in [CLIPBert](https://github.com/jayleicn/ClipBERT/blob/main/scripts/download_msrvtt.sh) to get the annotation data. To just get training and validation annotation, you can also run the download script:

```
bash msrvtt/download_msrvtt_train_val.sh
```

### LSMDC
TBD 

#### Citation

```
@inproceedings{park-etal-2022-exposing,
    title = "Exposing the Limits of Video-Text Models through Contrast Sets",
    author = "Park, Jae Sung  and
      Shen, Sheng  and
      Farhadi, Ali  and
      Darrell, Trevor  and
      Choi, Yejin  and
      Rohrbach, Anna",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.261",
    pages = "3574--3586",
}
```

Please email jspark96@cs.washington.edu for more information about the dataset.
